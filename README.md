# Unity Hand Tracking for AR/VR applications (Android)
### Overview & Agenda:
A sub-project for implementing hand tracking in mobile phones (Android) for AR/VR application (The main project being **The Haptic Response Glove**) using **MediaPipe**. **MediaPipe** is a multinodal machine learning pipeline developed by Google. It has various features ranging from Keypoint prediction to face detection. 
### Technologies used:
-Unity 2019.4.10f1
-ARFoundation 3.1.3
-MediaPipe(preview version)
### A walk through of working:
1. Let ARFoundation detect the nearest plane.
2. Push your hand on the detected plane and press **OK** button so that MediaPipe can track accurate depth of your hand w.r.t the phone.
3. By this step your hand must be tracked !
### GIFs and Video of working:
![4u6895](https://user-images.githubusercontent.com/77329786/104851813-38650400-591d-11eb-83bf-864648e2484c.gif)

[Link to thw video of demo of Hand Tracking on Mobile Phones](https://drive.google.com/file/d/1e5YcR_07-xnyi5psI3EMi9HRIhfw6Iv1/view?usp=sharing)
